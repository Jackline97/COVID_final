{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "white_final = pd.read_csv('white_final.csv',sep=',',encoding = \"ISO-8859-1\")\n",
    "maclious_final = pd.read_csv('maclious_final.csv',sep=',',encoding = \"ISO-8859-1\")\n",
    "sample_data_phish = pd.read_csv('data_phishtank.csv',sep=',',encoding = \"ISO-8859-1\")\n",
    "unlabeled_final = pd.read_csv('unlabeled_final.csv',sep=',',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekphrasis.classes.segmenter import Segmenter\n",
    "seg = Segmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maclious_final['Unified_url'][381])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_hostname_from_url(url):\n",
    "    hostname = url\n",
    "    # TODO: Put this pattern in patterns.py as something like - get_hostname_pattern.\n",
    "    pattern = \"https://|http://|www.|https://www.|http://www.\"\n",
    "    pre_pattern_match = re.search(pattern, hostname)\n",
    "\n",
    "    if pre_pattern_match:\n",
    "        hostname = hostname[pre_pattern_match.end():]\n",
    "        post_pattern_match = re.search(\"/\", hostname)\n",
    "        if post_pattern_match:\n",
    "            hostname = hostname[:post_pattern_match.start()]\n",
    "\n",
    "    return hostname\n",
    "\n",
    "temp = 0\n",
    "for url in unlabeled_final['Unified_url']:\n",
    "    hostname = get_hostname_from_url(url)\n",
    "    split_url = re.split(r'\\.',hostname)\n",
    "    if len(split_url) > 4:\n",
    "        temp+=1\n",
    "        print(url)\n",
    "print(temp)\n",
    "#     print(split_url)\n",
    "#     print(seg.segment(split_url[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dev-avira-free- antivirus'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg.segment(\"dev-avira-free-antivirus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n",
      "milk\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.classes.spellcorrect import SpellCorrector\n",
    "\n",
    "def wsp_tokenizer(text):\n",
    "    return text.split(\" \")\n",
    "sp = SpellCorrector(corpus=\"english\") \n",
    "puncttok = nltk.WordPunctTokenizer().tokenize\n",
    "\n",
    "social_tokenizer = SocialTokenizer(lowercase=False).tokenize\n",
    "\n",
    "print(sp.correct(\"mllk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
